[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Professor Emily Nordmann",
    "section": "",
    "text": "Associate Dean of Learning and Teaching\n\n\nUniversity of Glasgow\n\n\n\n   \n\n\n\n\n\nI am Associate Dean for Learning and Teaching and a Professor of Evidence-Informed Education at the University of Glasgow. My research predominantly focuses on lecture capture, how it can be used as an effective study tool by students and the impact on students from widening participation backgrounds as well as those with disabilities and neurodivergent conditions. In all my work, I draw on theories of learning from cognitive science and self-regulation, as well as theories of belonging and self-efficacy.\nMy leadership roles have centred around supporting those on the learning, teaching, and scholarship track. I am currently lead of the College of MVLS LTS Network and previously founded and led the Pedagogy and Education Research Unit in the School of Psychology and Neuroscience.\nI am based in the School of Psychology and Neuroscience. My teaching is varied although centres on cognitive psychology and beginner data skills in R and I am a vocal advocate of open science and open educational resources where as a member of the PsyTeachR team I has authored several open-access data skills books and tutorials."
  },
  {
    "objectID": "post.html",
    "href": "post.html",
    "title": "Blog",
    "section": "",
    "text": "Munro Tidy Tuesday\n\n\n\n\n\n\n\n\nAugust 31, 2025\n\n\nEmily Nordmann\n\n\n\n\n\n\n\n\n\n\n\n\nSupporting scholarship in yourself and others\n\n\n\n\n\n\n\n\nMarch 26, 2025\n\n\nEmily Nordmann\n\n\n\n\n\n\n\n\n\n\n\n\nFrom PERU, with love\n\n\n\n\n\n\n\n\nDecember 11, 2024\n\n\nEmily Nordmann\n\n\n\n\n\n\n\n\n\n\n\n\nMCQs in the age of AI\n\n\n\n\n\n\n\n\nOctober 26, 2024\n\n\nEmily Nordmann\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT: Student guidance for essays\n\n\n\n\n\n\n\n\nAugust 1, 2023\n\n\nEmily Nordmann\n\n\n\n\n\n\n\n\n\n\n\n\nFlexible Submission Windows\n\n\n\n\n\n\n\n\nAugust 23, 2022\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "netlify.html",
    "href": "netlify.html",
    "title": "netlify",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "netlify.html#quarto",
    "href": "netlify.html#quarto",
    "title": "netlify",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "index.html#biography",
    "href": "index.html#biography",
    "title": "Professor Emily Nordmann",
    "section": "",
    "text": "I am Associate Dean for Learning and Teaching and a Professor of Evidence-Informed Education at the University of Glasgow. My research predominantly focuses on lecture capture, how it can be used as an effective study tool by students and the impact on students from widening participation backgrounds as well as those with disabilities and neurodivergent conditions. In all my work, I draw on theories of learning from cognitive science and self-regulation, as well as theories of belonging and self-efficacy.\nMy leadership roles have centred around supporting those on the learning, teaching, and scholarship track. I am currently lead of the College of MVLS LTS Network and previously founded and led the Pedagogy and Education Research Unit in the School of Psychology and Neuroscience.\nI am based in the School of Psychology and Neuroscience. My teaching is varied although centres on cognitive psychology and beginner data skills in R and I am a vocal advocate of open science and open educational resources where as a member of the PsyTeachR team I has authored several open-access data skills books and tutorials."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Prof. Emily Nordmann",
    "section": "",
    "text": "PGCert in Teaching and Learning in Higher Education (e-learning), 2016\nUniversity of Aberdeen\n\nPhD in Psychology, 2013\nUniversity of Aberdeen\n\nMA in Psychology, 2008\nUniversity of Aberdeen"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Contact me by email at emily.nordmann@glasgow.ac.uk. You can also connect via social media although please do not DM on these platforms because I can only cope with managing one inbox and you won’t get a reply.\n\nEmail: emily.nordmann@glasgow.ac.uk\n\nLinkedIn: https://www.linkedin.com/in/emilynordmann/\n\nBlueSky: https://bsky.app/profile/emilynordmann.bsky.social"
  },
  {
    "objectID": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html",
    "href": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html",
    "title": "Supporting scholarship in yourself and others",
    "section": "",
    "text": "Today I visited Queen Mary University London where I met with the Teaching and Scholarship staff at the School of Biological and Behavioural Sciences. I was asked to talk about my career journey and advice for getting scholarship done myself as a researcher but also as someone who has engaged in leadership activities trying to support the scholarship of others. I started making notes and it got a bit long so I thought I might as well write it all down properly as it might be of use."
  },
  {
    "objectID": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#time-and-workload",
    "href": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#time-and-workload",
    "title": "Supporting scholarship in yourself and others",
    "section": "Time and workload",
    "text": "Time and workload\nLet’s get the elephant in the room that’s sitting on your head out the way – the first thing anyone needs to do scholarship is time. If SoTL is part of your promotion criteria then it should be an appropriate part of your workload. The first step is knowing exactly what proportion of your time – at Glasgow full-time LTS staff should have 20% (308 hours a year at 1FTE) allocated to scholarship activity. The second, much harder step, is actually protecting that time. As a manager and leader, you need to fight for your staff to have a functioning, transparent workload model, and listen to them when they tell you they don’t have the time and dig into the reasons. Sometimes it’s their total workload, sometimes it’s the balance of workload across the year, and sometimes it’s that people are not making good choices about how they spend their time. But they all have different solutions and you can’t start working on the appropriate one until you know the exact nature of the issue.\nAs a member of staff trying to do scholarship, I think it’s important to be realistic about the nature of academia. My 20% allocation could be viewed as a day a week but it would be unreasonable of me to demand that I get a day every single week to work on scholarship because that’s not how seasonal academia works - we’re essentially farmers with laptops, and sometimes the harvest has to take priority. Instead. I find it’s useful to take a longer view and think about the year as a whole. I know I will get very little done during term time but during the summer I might have whole weeks where I work on research. During those periods, I block out half or whole days in my diary and I consider them as immovable as all my other meetings. I don’t demand a day a week to do scholarship, but I do demand my 308 hours a year."
  },
  {
    "objectID": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#learn-to-say-no-but-remember-to-say-yes",
    "href": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#learn-to-say-no-but-remember-to-say-yes",
    "title": "Supporting scholarship in yourself and others",
    "section": "Learn to say no, but remember to say yes",
    "text": "Learn to say no, but remember to say yes\nRelated to the above, learning to say no is an important skill. My favourite line is “I’m afraid I don’t have capacity”. If it’s an opportunity that would benefit someone else, then put their name forward instead. If it’s an internal request, ask for something to be taken off you in replacement and go in with a solution. A common complaint about workload is that managers and models don’t take into account how long things actually take. If that’s the case, then take control and frame the conversation yourself and use your knowledge about your workload. You’re saying that doing X will take this much time, I can take that on if I give up Y.\nProtecting your time isn’t just about demands your employer places on you, think about how much you are giving to your students. I often frame the time we spend with students as “water workload” in that it will take up as much space as you give it. Have set office hours, set dissertation project meetings, set boundaries on replying to emails and expectations for your availability. Offer students the support they need and deserve, but not at personal cost to your wellbeing or career development. I have spoken to junior staff who never turn off their email and who offer each of their 10 project students an hour long meeting each week – we simply don’t have the time to do that. Also, I’d argue that’s not actually good for the students but we’re getting off-topic.\nBut also, remember to say yes. With the pressures of workload and everything else, being reminded to say no is very important. But if you say no to everything you will miss out on the opportunities that make the job fun, that allow you to meet interesting people, and that tick those boxes on the promotion form. You will never do scholarship if you never choose to do scholarship. If something has to burn, make the choice to let something else but your scholarship burn occasionally. This blog is too long and my colleagues will roll their eyes too hard if I tell this story for the 100th time but saying yes to something I thought I didn’t really have time to do ended up with me being interviewed about lecture capture opposite the Matterhorn."
  },
  {
    "objectID": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#knowledge-broker",
    "href": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#knowledge-broker",
    "title": "Supporting scholarship in yourself and others",
    "section": "Knowledge broker",
    "text": "Knowledge broker\nOne of the challenges I have faced trying to get SoTL done is ensuring I have the resource to do robust research. Sometimes this is about money but it’s more often about data and the fact that the nature of educational research means it’s reliant on observational, opt-in, self-report data with underpowered samples. A watershed moment for me was when I discovered the concept of “knowledge brokering”, the idea that you don’t have to do your own empirical research but instead you can have just as much impact being the conduit between the research and those who need it. A large part of what I do now is packaging up the literature in ways that are easy to digest for academics who don’t have educational expertise but just want to do things a little bit better – for example Lecture capture: Practical recommendations for students and instructors or Ten simple rules for supporting a temporary online pivot in higher education. Aside from trying to be useful, what these types of papers give me is control. I don’t need money or participants I can only access at a certain time of year to write these papers. I can write them when I have the time and thinking space to do so and they also don’t really require funding to conduct."
  },
  {
    "objectID": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#sotl-your-day-job",
    "href": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#sotl-your-day-job",
    "title": "Supporting scholarship in yourself and others",
    "section": "SoTL your day job",
    "text": "SoTL your day job\nBe strategic about what your scholarship focuses on. My main teaching and admin role has been with first year students, so my research focuses on study skills, self-regulation, and belonging. This means that my research informs my classroom and my classroom informs my research. I am a better first year lead than I was a decade ago because I can explain the theoretical basis of every part of the course, it’s all evidence-informed but also, it’s just efficient. If your research has nothing to do with your teaching and admin, the cognitive effort in switching gears will add friction. SoTL what you know and know what you SoTL. You also want to try and develop an area of expertise, something you’re known for. Mine is lecture capture and it’s the thing I always return to. I’m not saying don’t get distracted by shiny new topics and try new things, and when you’re first starting out, it can take time to find your niche. But, it helps to have a clear area of expertise as it makes it easier to become known for that area – someone who does everything is known for nothing."
  },
  {
    "objectID": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#money",
    "href": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#money",
    "title": "Supporting scholarship in yourself and others",
    "section": "Money",
    "text": "Money\nThis one is aimed at the managers and leaders. If you want your LTS staff to do high-quality, impactful SoTL you have to fund it appropriately. At UofG we have several SoTL-related funding schemes staff can apply for and I am lucky to be in a School that has a generous travel fund. As I write this the sector is in a death spiral and I know the reality for many is very far away from what I have access to and I recognise my privilege. But it doesn’t make it any less true that some level of resource is needed to transform SoTL from a course level evaluation to impactful, robust research that is disseminated properly, and if the only thing I can do to help is to say that out loud, then at the very least I can say it out loud."
  },
  {
    "objectID": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#collaboration-community-and-mentoring",
    "href": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#collaboration-community-and-mentoring",
    "title": "Supporting scholarship in yourself and others",
    "section": "Collaboration, community, and mentoring",
    "text": "Collaboration, community, and mentoring\nI’m also lucky that I work in a large LTS team so we have a very strong community of scholarship support. But in other Schools the LTS team is smaller and so we also have an institutional SoTL network that brings people together and this network does vital work. You’re much more likely to be successful at SoTL when you work with other people and when you can share skills and expertise and workload – my mantra has been to try and do more with less, to aim for fewer projects that actually make it to output.\nI’ve also found social media to be a great networking tool and it’s allowed me to work with the best people rather than just the nearest people. These kind of communities also allow for both formal and informal mentoring. When staff are starting out on their SoTL journey, my advice is to get involved with an existing project with someone a bit further down the line and this is particularly important for those LTS staffs whose discipline research and expertise is very far away from education research. Making the jump can be hard, but it’s much easier in collaboration."
  },
  {
    "objectID": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#dont-wait-for-stuff-to-come-to-you",
    "href": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#dont-wait-for-stuff-to-come-to-you",
    "title": "Supporting scholarship in yourself and others",
    "section": "Don’t wait for stuff to come to you",
    "text": "Don’t wait for stuff to come to you\nNominate yourself for awards, ask to be invited for a talk, put yourself forward for things you want to do. Lots of stuff isn’t in our control but you have to be in the race to win it. Similarly, make sure that you have access to sources of information about SoTL related funding, conferences, journals, and other opportunities. My main source of information for this type of thing is social media – LinkedIn and Bluesky these days. Social media isn’t for everyone and that’s fine but in that case, sign-up to mailing lists (e.g., the SEDA list) or join an organisation like ESPLAT. No-one is going to come chasing you with information, you need to do something to find it."
  },
  {
    "objectID": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#for-the-love-of-god-share-what-you-do",
    "href": "post/2025-03-26-supporting-scholarship-in-yourself-and-others/index.en.html#for-the-love-of-god-share-what-you-do",
    "title": "Supporting scholarship in yourself and others",
    "section": "For the love of god, share what you do",
    "text": "For the love of god, share what you do\nAnd finally, for the love of god, tell people about your work! Again, social media isn’t for everyone and that’s fine, but if it’s not for you then go to a conference, find other ways of networking, write a blog, send out a carrier pigeon. If the work was worth doing, it’s worth getting out there properly and it’s a more efficient use of time to wring every bit of impact out of one paper than it is to write 5 papers that no-one reads. I get asked how I manage to get so many invited talks and the main reason is that I have put a huge amount of work into promoting my work -it’s not an optional extra, dissemination should be part of your project plan."
  },
  {
    "objectID": "post/2022-08-23-flexible-submission-windows/index.html",
    "href": "post/2022-08-23-flexible-submission-windows/index.html",
    "title": "Flexible Submission Windows",
    "section": "",
    "text": "Like many, the number of extension requests on my course increased over the last two years. This is not a “OH THOSE BLOODY STUDENTS” post. I don’t blame students for any of the problems we’re seeing now, I blame the pandemic. But more importantly there doesn’t need to be anyone at fault for there to be an issue we need to address and what we’ve seen is that giving out unlimited extensions isn’t really seeming to be helping anyone. Students’ ability to self-regulate and manage their time hasn’t developed as we would typically expect which is important because time management is suggested to have a relationship with academic performance and anxiety. Additionally, the staff workload associated with managing the volume of extensions and the knock-on effects on marking timelines and the return of feedback is simply untenable.\nThis also isn’t a post whereby I am going to suggest returning to a punitive, regressive system that bakes in ableism and classism. Providing flexibility and understanding that your students have complex lives and commitments beyond your course is a good thing (and that’s before we really feel the effect of students needing to work more because of the cost-of-living crisis).\nWe know that major coursework deadlines tend to cluster around the same points in the semester and given the structure of the academic year, there’s limited ways we can get around this, but also, learning to manage and prioritise multiple deadlines is a useful skill to develop. I am guilty myself of complaining that students don’t look at all their deadlines and work on them at different times to avoid the clustering effect. I am also guilty of saying yes to too many talk invitations in March because I think “teaching will be over” and I ignore what 15 years of experience has taught me. It is almost as if the problem is not “being a student” and instead “being a busy human”.\nSo this year, I am going to try and reframe how I talk about deadlines on my course and (hopefully) how students think about them by piloting Flexible Submission Windows. This is inspired by research that has shown that time management training can help students work more effectively although realistically I have no idea if this is going to work. Traditionally, our assignment deadlines are Friday at 12 noon, and we open the submission portal on Moodle a week before. We may get a handful of submissions in this week, but the majority come in the 12 hours before the deadline. I could complain about this but I could also accept that if I only promote a single fixed deadline, I am encouraging behaviour that focuses on a single fixed, final deadline.\nThese are the instructions for the essay submission this year:\n\nFor this assessment you have a flexible deadline window. You may submit your essay from Monday 7th November at 12 noon until the final deadline of Friday 11th November at 12 noon.\nTo help with your time management, you should review any other deadlines and commitments you have at this time, and decide which day during the flexible window works best for you. You will be asked in reading week to make a note of which day you plan to submit – this isn’t binding but explicitly making a choice may help you plan better.\nWe encourage you to plan to submit your essay early so that if you need a few extra days you can still meet the final deadline – if the day you submit your essay is different to the one you intended, you don’t need to inform anyone as long as you still submit within the window.\nMarks and feedback for those essays submitted within the window will be released on X.\nIf you need an extension beyond the final deadline, please see the Extensions & Good Cause guidance. Your extension request should explain why you were unable to submit during the flexible window.\n\nWe have a reading week in the middle of the semester where there is no formal teaching but students are encouraged to use the time to work on their assignments ahead of the deadline in week 8. In this week, I am going to ask students to note which day they intend to submit the essay on – this won’t be binding, rather, I’m trying to see if the Theory of Planned Behaviour is up to any good. We’re also not going to refuse extension requests – if students need extra flexibility it will still be offered.\nAs I’ve said, I don’t know if this is going to work and what unintended consequences it might have in terms of administration workload or student behaviours, which is why it’s a pilot. I will be evaluating it by comparing the number of extension requests and late submissions to last year, the profile of when assignments were submitted across the week, and I’m also going to explicitly ask students for their feedback on the system.\nWhat I want is to try and reframe the deadline so that they’re not aiming for a single fixed point in time that if they miss it, requires an extension. I’m not expecting that the majority of essays will be submitted at the start of the window. What I’m hoping for is that I can encourage as many students as possible to aim for a slightly earlier submission which means that when they inevitably need an extra day or two (because this is their first university assignment and it’s hard to know how long things take) they can still meet the final deadline which means they don’t get any of the worry associated with asking for an extension or submitting late, and we also minimise the workload associated with extensions and late submissions.\nEssentially, the skill I want to help students develop isn’t “you must always meet all deadlines” it’s “always build in a buffer because life will get in the way (and stop saying yes to talks in March)”."
  },
  {
    "objectID": "post/2023-08-01-chatgpt-student-guidance-for-essays/index.en.html",
    "href": "post/2023-08-01-chatgpt-student-guidance-for-essays/index.en.html",
    "title": "ChatGPT: Student guidance for essays",
    "section": "",
    "text": "Part 1: Using ChatGPT to create teaching materials: Data simulation & MCQs\nPart 2: Using ChatGPT to create teaching materials: marking criteria & rubrics\nPart 3: ChatGPT: Student guidance for multiple-choice assessments\nPart 4: Using ChatGPT for learning & teaching: Correcting auto-transcripts\nYou could argue that these blogs are an exercise in procrastination and if you spend any time with me in real life, you’ll be questioning why I’m writing all these whilst constantly moaning about workload. If I’m completely honest they are part-procrastination, but, genuinely, I’m much further along than if I hadn’t spent the time on these blogs as the process of writing has helped shaped my thoughts.\nI’ve been working on the guidance for my Level 1 essay and in some ways, writing guidance for MCQs was more problematic in that ChatGPT can get them all right very quickly. But in other ways, what is and is not academic misconduct was so clear with MCQs and it’s so much harder to draw the lines in the sand when it comes to an essay and provide good advice on how students can and should use AI. I’m so much less sure of myself with the essay guidance. I’ve structured it under three subheadings although this may well change between now and September (and feedback and ideas are most welcome!). I think it’s starting to look ok but my sense of unease remains."
  },
  {
    "objectID": "post/2023-08-01-chatgpt-student-guidance-for-essays/index.en.html#what-use-of-ai-would-be-regarded-as-academic-misconduct-for-this-assessment",
    "href": "post/2023-08-01-chatgpt-student-guidance-for-essays/index.en.html#what-use-of-ai-would-be-regarded-as-academic-misconduct-for-this-assessment",
    "title": "ChatGPT: Student guidance for essays",
    "section": "What use of AI would be regarded as academic misconduct for this assessment?",
    "text": "What use of AI would be regarded as academic misconduct for this assessment?\n\nUsing AI to write any part of your essay for you from scratch is academic misconduct and if we suspect you have used it in this way, we will report you for academic misconduct.\n\n\nAn easy rule of thumb to follow for the essay is do not copy and paste anything from an AI into your essay. This doesn’t avoid every problem, and there are exceptions to the rule, but if you want a simple rule to follow, that’s a good starting point.\n\n\nUse AI to help you refine and edit your essay, do not use it to write the essay. When in doubt, come and ask talk to us in office hours - you will not get in trouble for asking how to do things right!\n\nIt’s all shades of grey but I wanted to provide as much clarity as I could. The “don’t copy and paste” rule isn’t perfect but it probably works well enough to give the right idea. By explicitly noting they may not be sure and could reach out for help, I also wanted to highlight that this isn’t an exact art and it’s not wrong for them to have questions."
  },
  {
    "objectID": "post/2023-08-01-chatgpt-student-guidance-for-essays/index.en.html#how-can-i-use-ai-to-help-support-my-learning-for-this-assessment",
    "href": "post/2023-08-01-chatgpt-student-guidance-for-essays/index.en.html#how-can-i-use-ai-to-help-support-my-learning-for-this-assessment",
    "title": "ChatGPT: Student guidance for essays",
    "section": "How can I use AI to help support my learning for this assessment?",
    "text": "How can I use AI to help support my learning for this assessment?\n\nYou can use specific AI tools to help with your literature search (but do not use ChatGPT for this! See below for more info):\n\n\nTools like Elicit or Connected Papers can find relevant papers without perfect keyword match, summarise takeaways from the paper specific to your question, and extract key information from the papers. It’s not academic misconduct to use Elicit because you still have to read the papers, understand the information, and integrate it into your essay.\n\n\nYou can use tools like ChatGPT to get feedback and use it to help you refine and edit (but not write!) your essay. For example, you can use it to get feedback on your draft essay plan. This is a good use of AI because you’re using it to get feedback but you’re playing an absolutely active role in the creation of your essay.\n\n\nExample prompt: Act as an expert psychology tutor. I am a first year undergraduate psychology student and have to write an essay on the question [give it your essay question]. Here is the marking criteria [give it the marking criteria]. And here is a draft structure I have written to plan my essay [give it your essay plan]. I want you to give me feedback on how I can improve my essay plan, but before you give any feedback, ask me up to 5 questions about my plan and use my answers to inform your feedback.\n\n\nYou can also use it to give you feedback on your draft essay before you submit it. As with using it for feedback on your plan, this is a good use of AI because you’re using it in an active way and any changes to your essay will be your own work, you’re just getting direction form it.\n\n\nExample prompt: Act as an expert psychology tutor. am a first year undergraduate psychology student and have to write an essay on the question [give it your essay question]. Here is the marking criteria [give it the marking criteria]. Give me feedback on my essay for each of the marking criteria.\n\nTo test out using it for feedback I got ChatGPT to write me a draft essay plan and essay and then I fed the snake it’s own tail and asked for feedback in a new chat window. The feedback it produced was not always up to what a human would produce (although let’s face it, that depends on the human) and there’s a need to urge caution but as a supplement rather than a replacement, I think this would be a useful form of formative feedback - here’s an example of the feedback it gave aligned with the marking criteria:\n\n3.2 Ensure that the essay has a logical structure and that the paragraphs flow together to form a coherent narrative: The structure of your essay is good, with an introduction, main body, and conclusion. The narrative flow between paragraphs is generally effective, but there are a few places where transitions could be smoother. Additionally, some paragraphs may be too long or too short, affecting the overall coherence of the essay. Consider reorganizing and editing for better flow and readability.\n\nIt is quite general but I would prefer general to overly specific and the important thing here is that ChatGPT isn’t doing any of their work, they still have to action the feedback. I would also be really interested to know if there’s a difference in how students respond to AI vs human feedback - I would imagine they’d be more likely to assume the human was right but also coming from an AI probably strips the feedback of its emotion which might make them more likely to process it? Interesting times ahead.\nI also wanted to address the use of ChatGPT for editing. Most of my thoughts on this came out of trying to use it for correcting auto-transcripts where I really struggled to get it to do exactly what I wanted. My key concern here is students giving it their essay and then whether they wanted it to or not, ChatGPT editing the entire thing and changing the meaning of what they’ve written and stripping their writing of any individuality. I want them to make active, conscious choices and to learn from the editing process not just take what it gives them without thinking.\n\nFinally, you can use it to help you proof-read and edit. Be very careful to ask it to provide you with line-by-line changes with the comparison so that you can see what it has changed and why, because it means you’re making an active choice and it will also help you learn about how to improve your writing.\n\n\nBefore you use AI for editing, remember that it is important that you develop your own voice as a writer and if you constantly use AI to edit you’ll end up with a bland, generic writing style. If everyone does this we’re going to end up with a world written in beige. Don’t be beige. Also remember that just because the AI suggests an edit, doesn’t mean it is better than what you’ve written! Even with the below prompts it may edit more than you ask it to - if it does this and edits huge paragraphs rather than individual sentences, ignore it and click regenerate response - you want it to give you the edits line-by-line so that you can compare them and choose the ones you think are actually an improvement.\n\n\nExample prompt: Act as an expert academic writing tutor. I have written an undergraduate university essay and I would like you to review it with regards to spelling, grammar, concise writing, APA formatting, and academic tone. Provide suggestions for edits I can make sentence-by-sentence. Provide the original and your edited suggestion so that I can compare them. Explain why you have suggested the edit [give it your essay]:\n\n\nExample prompt if English is not your first language: Act as an expert academic writing tutor. My first language is [your first language]. I have written an undergraduate university essay and I would like you to review it with regards to ensuring that the writing follows the grammar rules and conventions of British English. Provide suggestions for edits I can make sentence-by-sentence. Provide the original and your edited suggestion so that I can compare them. Explain why you have suggested the edit [give it your essay]\n\nI am terrified that I am pointing them towards a tool that will potentially harm their development as writers, either because they will blindly copy and paste and end up changing the meaning of what they intended, or that we’ll end up in a world where everyone has the same generic A-corrected writing.\nBut, abstinence as a policy isn’t going to work - if we don’t guide them they’re going to do it anyway, my logic here is that at least this way I can make them aware of the potential pitfalls.\nI am also very likely romanticising the need to develop an individual writing voice based on my own feelings about writing. As I write this I’ve got George Orwell’s rules for writing swirling around in my head, the fact that I know them by heart should tell me I might have crossed the line into wanky academic. Maybe losing some individuality is the price we pay for massively improving the clarity of most people’s writing (I vehemently don’t believe this but I feel like I should at least provide the other side of the argument)?."
  },
  {
    "objectID": "post/2023-08-01-chatgpt-student-guidance-for-essays/index.en.html#what-are-the-limitations-of-using-ai-for-this-assessment-and-what-should-i-be-careful-of-aside-from-academic-misconduct",
    "href": "post/2023-08-01-chatgpt-student-guidance-for-essays/index.en.html#what-are-the-limitations-of-using-ai-for-this-assessment-and-what-should-i-be-careful-of-aside-from-academic-misconduct",
    "title": "ChatGPT: Student guidance for essays",
    "section": "What are the limitations of using AI for this assessment and what should I be careful of aside from academic misconduct?",
    "text": "What are the limitations of using AI for this assessment and what should I be careful of aside from academic misconduct?\nIn addition to the above caveats, I have a standard heading about limitations to try and get them thinking more critically about AI and not just focus on the issue of misconduct.\n\nDo not use AI tools like ChatGPT to do your research. Use tools like Scopus, Web of Science, Google Scholar, ad Elicit and read the papers yourself. The reasons for this are that: a) if you rely on AI summaries you won’t develop the depth of understanding you need at university level and your essay will be shallow b) reading papers helps you develop an academic tone in your writing c) sometimes it tells you things that are simply wrong, including making up references that don’t exist d) it doesn’t have access to the most recent research.\n\n\nIf you use it for feedback, it may give you advice that isn’t very good and if you’re not super careful about ensuring you’ve given it all the guidance from the labs and your tutor, it may end up telling you to do something that contradicts what we’ve told you to do. If you do use AI to help refine your structure, we’d strongly encourage you to come to office hours or GTA sessions to check you’re on the right track.\n\n\nAI writing is frequently formulaic, uninspiring, and often doesn’t have the right tone.\n\n\nWhen you ask it to suggest edits for your work, you have to be really careful to review its suggestions because sometimes it will change the core meaning of what you’ve written rather than just correcting the grammar or tone. Always ask it to give you suggestions sentence-by-sentence and if it doesn’t do this, try changing the prompt or regenerate the response until it does. Remember that your version might be better than than the AI - trust yourself!\n\n\nAnother use case we’ve seen is using AI to correct your references into APA formatting, but having tried this, it didn’t do a very good job so we’d suggest using a reference manager like Zotero instead if you want something to help automate that process (although you still need to check them).\n\nIs this the best approach? I’m not sure. But I am fairly sure that right now, at scale, honesty and transparency is the only tool we’ve got that’s of any use. I know that some students will abuse it, and some will likely take my guidance to abuse it even more effectively. But I have always believed that we shouldn’t design learning & teaching around the lowest common denominator and that the overwhelming majority of students want to, and do, do things as intended so we should give them what information we do have whilst we’re still figuring it out on our side.\nGod I hope I’m right.\n\nAbout halfway through writing this blog I got the song “Walk through the fire” from the Buffy musical stuck in my head like the millennial I am so let’s end with that.\nWill this do a thing to change it? Am I leading them to danger? Are we all too far gone to care?"
  },
  {
    "objectID": "post/2024-12-11-from-peru-with-love/index.en.html",
    "href": "post/2024-12-11-from-peru-with-love/index.en.html",
    "title": "From PERU, with love",
    "section": "",
    "text": "Today was my last official event as Centre Head for the Pedagogy and Education Research Unit (PERU), and I wanted to take the opportunity to talk about why I think organisations like PERU are so important for education-focused academics and to summarise what we’ve done over the last two years, and why, in the hope it might provide a template for others. If you’re interested in keeping up with PERU after reading this, you can follow us on LinkedIn.\nPERU was formally established in 2022 as a response to our unique position as a very large LTS (Learning, Teaching, and Scholarship) team - I believe that the School of Psychology and Neuroscience is the biggest LTS team at the University of Glasgow with more than 30 full-time, permanent members of staff and I imagine we’re also one of the largest in the country.\nWe agreed on our structure and wrote our strategy through a series of collaborative workshops where we worked together to define PERU’s purpose and values and after several iterations and much discussion, settled on three research themes:\n\nApplied Cognition and Learning in Teaching, which focuses on evidence-based strategies to enhance student engagement and learning outcomes.\n\nAccess, Inclusion, and Wellbeing, which centres on equity, accessibility, and fostering a supportive environment for both staff and students.\n\nOpen Science and Pedagogy, which champions transparency, reproducibility, and the development of open educational resources.\n\nIt was also really important to me that we had a full strategy, so in a later activity, we formalised our values:,\n\nCollaboration and Support: At its core, PERU aims to provide a community of support and promote professional development through collaboration, transparency, trust, and fairness.\nOpenness: All work conducted by PERU embraces openness, either through the adoption of open scholarship practices in our research, or by ensuring our work is available as an open educational resource.\nInclusivity and Accessibility: Enhancing student and staff experiences by breaking down barriers to accessibility and fostering a sense of belonging is a core value of not only what we work on, but how we work as a team by ensuring that all staff have the opportunity and resource to develop professionally.\nIntegrity and Excellence: PERU is committed to upholding high standards of evidence-based scholarship and excellence in research. We prioritise quality over quantity and demand no less of our scholarship than would be expected of any other research field.\n\nSet concrete outcomes:\n\nAll LTS staff are research-active in an area that supports their professional development and the PERU strategy.\nOur work shapes educational practices and policies through the adoption of PERU research and outputs by others, nationally and internationally.\nWe achieve national and international recognition through awards, promotions, and fellowships.\nWe disseminate research findings through outlets such as peer-reviewed articles, national and international educational blogs, and external workshops and conference presentations.\nWe secure sources of internal and external funding.\n\nAnd agreed on what we needed in the form of enabling factors to achieve those outcomes, so that we could hold the School, and ourselves, to account:\n\nA fair and transparent workload model that ensures all LTS staff have time to conduct scholarship.\nInternal funding to support the development of research projects where other funding is not available, and to support dissemination and networking.\nRegular PERU sessions to help identify common themes and opportunities for collaboration.\nContinuous professional development and support, specific to the LTS track, and focused on scholarship and esteem across all grades.\n\nOur formalisation as a unit has been essential in validating the LTS team as researchers and in making the distinction between our teaching and scholarship activity (I teach, but I am not a teacher, I am an LTS academic). We are different to the other research centres in that we don’t participate in the REF and we don’t have funding targets (well, other than those pesky tuition fees and student numbers) but it’s so important that we still have a seat at the table and I’m also grateful to have a very supportive Head of School in Prof. Kate Jeffrey.\nIn many other Schools and institutions, LTS academics work in much smaller teams which can limit opportunities for collaboration, and at worst, can be isolating. In those cases, institution-wide SoTL Networks that provide breadth of expertise, professional development, and a sense of community are vital. But our size makes us different. Whilst our student numbers have presented us with challenges for teaching (everything must be designed for scale), when it comes to our scholarship, our size gives us a rare opportunity to build a strong internal community within the School where collaboration, support, and professional identity can thrive.\nAnd I think that this sense of identity and belonging is PERU’s greatest strength. It’s why when I hear people refer to themselves as part of PERU or talking about PERU to external colleagues it makes me so incredibly happy. It’s well-established that belonging is key to student success and that students tend to feel a greater sense of belonging to their School and subject rather than their University as a whole. Same goes for us. Identity and shared purpose and vision are so important, and they’re a big part of why we’ve been able to achieve so much. I will also note that you don’t have to be as big as us to organise into something like PERU, but this doesn’t detract from the point that the bigger you are, the more sense it makes to do so.\nFormalising the structure of PERU has also allowed us to take full advantage of the School-level resources available. While many LTS teams across the sector operate with little to no support, we’re lucky to have a School management team and environment that supports us with conference and travel funds, and with project funds (in addition to institutional funding for Learning and Teaching Development, Scholarship, and Staff-Student Partnerships). Our research tends to be cheap in relative terms, but it doesn’t happen for free and to have impact it needs disseminated and to thrive we need professional development and networking opportunities. If institutions create education-focused tracks that don’t/can’t apply for grants but also expect high quality scholarship then they better be dammed well willing to support it. Glasgow isn’t perfect but in this I think we lead the sector in putting our money where our expectations are.\nI’m incredibly proud of everything we’ve achieved. When PERU was first formed, I didn’t realise how much it would come to mean to me. I thought it would be just another admin role, but it’s been a source of immense joy. That said, it’s also absolutely the right time to hand it over to a fresh pair of eyes and I’m delighted to have Dr. Ashley Robertson take the lead. Her focus on supporting early-career colleagues and driving research outputs will build on what we’ve already established and I can’t wait to come along for the ride."
  },
  {
    "objectID": "post/2025-08-31-munro-tidy-tuesday/index.en.html",
    "href": "post/2025-08-31-munro-tidy-tuesday/index.en.html",
    "title": "Munro Tidy Tuesday",
    "section": "",
    "text": "I was immediately obsessed when I saw the Tidy Tuesday theme was Scottish Munros - we have climbed 58/282 so far. As I assume is the case for the majority of baggers, we use walkhighlands for all our munro info and routes. walkhighlands is one of the unequivocally wonderful bits of the internet and I can’t believe it’s free. We donate to keep it going, and if you’re a bagger who uses it often, I’d encourage you to do the same. When I saw the Tidy Tuesday dataset, I knew I wanted to try and combine the provided data from the Database of British and Irish Hills v18.2 with what’s available on walkhighlands.\nBecause I’ve made certain career choices, my day-to-day activity now involves a lot less coding and a lot more admin and I realised I was starting to lose some of my R so this has been a nice excuse to refresh. I’m gearing up for another semester of teaching R to students in the age of AI and it has been interesting to reflect on how I’m using AI myself. Pleasingly, many of the solutions to the many problems I had to solve came from my knowledge of Munros and Gaelic. AI sometimes provided the code but it’s a nice reminder it can only provide the answers to questions you know to ask."
  },
  {
    "objectID": "post/2025-08-31-munro-tidy-tuesday/index.en.html#walkhighlands-munro-info",
    "href": "post/2025-08-31-munro-tidy-tuesday/index.en.html#walkhighlands-munro-info",
    "title": "Munro Tidy Tuesday",
    "section": "Walkhighlands munro info",
    "text": "Walkhighlands munro info\nThe reason I wanted to use walkhighlands data is that it has a bunch of route information that I could use for exploration that wasn’t contained in the Database of British and Irish Hills that is the base of the Tidy Tuesday data:\n\nRegion\nEstimated length of walk in hours\nDistance of walk\nTotal ascent of route (not just of each individual Munro)\nRoute descriptions\n\nI’ve decided not to include the code I used for web scraping from walkhighlands. There’s nothing in their terms of service I can find that says I shouldn’t have done it, but I don’t want to annoy them because again, they’re the best thing on the internet so I’ll just describe roughly what I did.\nThe approach was to first scrape walkhighlands for the list of Munros, the region in which they are located, and their height from the Munro A-Z page. Then it took one route for each munro (the first listed), the min and max estimated walk time, distance in km, total ascent in metres, and used regex to look for certain words that describe walk features that might be of interest (scramble, exposed, arete, river, spate, bog). walkhighlands also provides a Grade rating for each walk as well as a bog factor, however, these are represented as images, and try as I (well, AI) might, I could not get it to parse this information.\n\nAn important note for those of you who are familiar with walkhighlands, as noted, I included one route per munro - the first one listed. This can make a big difference to the walk, for example, which route you take up Ben Nevis significantly changes the fear factor and technicality. Text mining is also a blunt tool and only looks at whether a word is contained in the walk report rather than its context - a route that reads “there is no scrambling required” would still have been included in the “scramble” category.\nIt took a long time to get the AI to provide code that worked and there were a number of issues - at one point it was matching the route to the wrong Munro, then it didn’t return all Munros, then it was missing a bunch of routes. I had to manually create a file of some routes to load in because I could not find a solution as to why these handful were failing. Because I could not have done any of this type of scraping without AI, I really have no idea why it works and why it didn’t. This is intellectually unsatisfying but also, the idea you’d be willing to trust this black box of “knowledge” to something more serious than an obsessive deep dive into your favorite mountains is madness.\nHere’s what the walkhighlands data looks like.\n\n\nmunroregionheightfirst_route_titlefirst_route_urlscrambleexposedspatebogriveraretetime_hours_mintime_hours_maxdistance_kmascentA' Bhuidheanach BheagCairngorms936Càrn na Caim and A' Bhuidheanach Bheag from Drumochterhttps://www.walkhighlands.co.uk/cairngorms/carn-na-caim.shtmlFALSEFALSEFALSETRUEFALSEFALSE5619824A' Chailleach (Fannichs)Ullapool997Sgùrr Breac and a' Chailleach from near Braemorehttps://www.walkhighlands.co.uk/ullapool/sgurrbreac.shtmlFALSEFALSEFALSETRUEFALSEFALSE68161,127"
  },
  {
    "objectID": "post/2025-08-31-munro-tidy-tuesday/index.en.html#database-of-british-and-irish-hills",
    "href": "post/2025-08-31-munro-tidy-tuesday/index.en.html#database-of-british-and-irish-hills",
    "title": "Munro Tidy Tuesday",
    "section": "Database of British and Irish Hills",
    "text": "Database of British and Irish Hills\nNext it was time to load in the Tidy Tuesday dataset which is from the Database of British and Irish Hills. In order to be able to join this with my walkhighlands database, I had to do quite a lot of wrangling although thankfully I was not reliant on AI and mainly able to achieve it because of my existing knowledge of Munros and Gaelic.\nI wasn’t that bothered about the Munro status changes over the years as the walkhighlands database allowed me to do other more interesting analyses so I dropped these bits.\n\n\nShow code\nlibrary(tidyverse)\nlibrary(fuzzyjoin)\nlibrary(ggthemes)\nlibrary(ggridges)\nlibrary(flextable)\nlibrary(stringi)\nlibrary(tidytext)\nlibrary(sf)       \nlibrary(plotly)\nlibrary(rnaturalearth)\n\nscottish_munros &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-08-19/scottish_munros.csv')\n\nraw_data &lt;- read_csv(\"https://www.hills-database.co.uk/munrotab_v8.0.1.csv\")\n\nscottish_munros &lt;- raw_data |&gt;\n  filter(`2021` == \"MUN\") |&gt;\n  select(\n    `DoBIH Number`, Name,\n    `Height (m)`, xcoord, ycoord, \"Grid Ref\",\n  ) |&gt;\n  drop_na(`DoBIH Number`) |&gt; \n  rename(\n    munro = \"Name\",\n    height = `Height (m)`,\n    number = `DoBIH Number`,\n    grid_ref = \"Grid Ref\"\n  ) \nrm(raw_data)"
  },
  {
    "objectID": "post/2025-08-31-munro-tidy-tuesday/index.en.html#whats-in-a-name-issues",
    "href": "post/2025-08-31-munro-tidy-tuesday/index.en.html#whats-in-a-name-issues",
    "title": "Munro Tidy Tuesday",
    "section": "What’s in a name (issues)",
    "text": "What’s in a name (issues)\nThe first problem to solve before trying to join the two datasets was that some of the names of the Munros differ between the two - sometimes this is because there are variants in the Gaelic (Carn Eighe/Càrn Eige), sometimes the Anglicised version is used, and sometimes it’s because multiple Munros have the same name so they have additional information added in parenthesis in one of the files (Stuc an Lochain [Stuchd an Lochain]/Stùcd an Lochain).\n\n\nShow code\nscottish_munros &lt;- scottish_munros |&gt;\n  # Standardise names in the 'dobih' dataset to Walkhighlands spellings\n  mutate(\n    munro = case_when(\n      munro == \"A' Chraileag [A' Chralaig]\" ~ \"A' Chralaig\",\n      munro == \"Beinn Challuim [Ben Challum]\" ~ \"Ben Challum\",\n      munro == \"Beinn Sheasgarnaich [Beinn Heasgarnich]\" ~ \"Beinn Heasgarnich\",\n      munro == \"Beinn a' Bhuird North Top\" ~ \"Beinn a' Bhùird\",\n      munro == \"Ben Klibreck - Meall nan Con\" ~ \"Ben Klibreck\",\n      munro == \"Blabheinn [Bla Bheinn]\" ~ \"Blà Bheinn\",\n      munro == \"Cac Carn Beag (Lochnagar)\" ~ \"Lochnagar\",\n      munro == \"Carn Eighe\" ~ \"Càrn Eige\",\n      munro == \"Carn a' Choire Bhoidheach\" ~ \"Càrn a' Choire Bhòidheach\",\n      munro == \"Creag a' Mhaim\" ~ \"Creag a'Mhàim\",\n      munro == \"Glas Leathad Mor (Ben Wyvis)\" ~ \"Ben Wyvis\",\n      munro == \"Leabaidh an Daimh Bhuidhe (Ben Avon)\" ~ \"Ben Avon\",\n      munro == \"Meall Garbh\" ~ \"Meall Garbh (Ben Lawers)\",\n      munro == \"Meall na Aighean\" ~ \"Creag Mhòr (Meall na Aighean)\",\n      munro == \"Sgurr Dearg - Inaccessible Pinnacle\" ~ \"Inaccessible Pinnacle\",\n      munro == \"Sgurr Mhor (Beinn Alligin)\" ~ \"Sgùrr Mòr (Beinn Alligin)\",\n      munro == \"Sgurr na h-Ulaidh [Sgor na h-Ulaidh]\" ~ \"Sgòr na h-Ulaidh\",\n      munro == \"Sgurr nan Ceathramhnan [Sgurr nan Ceathreamhnan]\" ~ \"Sgùrr nan Ceathreamhnan\",\n      munro == \"Stob Coir' an Albannaich\" ~ \"Stob Coir an Albannaich\",\n      munro == \"Stuc an Lochain [Stuchd an Lochain]\" ~ \"Stùcd an Lochain\",\n      munro == \"Càrn nan Gobhar (Strathfarrar)\" ~ \"Càrn nan Gobhar (Loch Mullardoch)\",\n      TRUE ~ munro\n    )\n  )\n\n\nAfter standardising the names, to facilitate the join I also had to convert to lower case, remove accents (whether they’re used differs between the datasets), and any parenthesis information from the Munro names.\nAfter this cleaning, because multiple Munros have the same name, I needed to join on height to distinguish them as thankfully, there aren’t two Munros with the same name and height. However, a problem I wasn’t anticipating is that height measurements differed between the datasets. A lot of these can be put down to rounding - walkhighlands uses whole numbers whilst the DoBIH uses two decimal places. However, this doesn’t explain them all (the largest difference is 8.1 metres, that’s a lot!). I don’t know which one is “correct” or why they differ but given DoBIH is numerically more precise, I decided to use that as my measure of height in any analysis.\nMy AI-fuelled discovery was fuzzyjoin which allows you to set a tolerance level for the join and pick a best match. I’ve never needed this before but it provided itself to be extremely useful - with a bit of trial and error I set a tolerance of 10m and manually checked the output to ensure everything had lined up correctly.\n\n\nShow code\n# 0) Choose a tolerance in metres (use Inf if you want “nearest regardless”)\ntol_m &lt;- 10\n\n# 1) Normalise names in BOTH tables: remove (...) and [...], drop accents, lower-case, squish\nx &lt;- walkhighlands %&gt;%\n  mutate(\n    munro_key = munro %&gt;%\n      str_replace_all(\"\\\\s*\\\\([^)]*\\\\)\", \"\") %&gt;%   # remove text in ( )\n      str_replace_all(\"\\\\s*\\\\[[^\\\\]]*\\\\]\", \"\") %&gt;% # remove text in [ ]\n      stri_trans_general(\"Latin-ASCII\") %&gt;%\n      str_to_lower() %&gt;%\n      str_squish(),\n    height = parse_number(as.character(height)),\n    row_id_x = row_number()\n  )\n\ny &lt;- scottish_munros %&gt;%\n  mutate(\n    munro_key = munro %&gt;%\n      str_replace_all(\"\\\\s*\\\\([^)]*\\\\)\", \"\") %&gt;%\n      str_replace_all(\"\\\\s*\\\\[[^\\\\]]*\\\\]\", \"\") %&gt;%\n      stri_trans_general(\"Latin-ASCII\") %&gt;%\n      str_to_lower() %&gt;%\n      str_squish(),\n    height = parse_number(as.character(height)),\n    row_id_y = row_number()\n  )\n\n# 2) Fuzzy FULL join on exact munro_key + height within tolerance\ncandidates &lt;- fuzzy_full_join(\n  x, y,\n  by = c(\"munro_key\" = \"munro_key\", \"height\" = \"height\"),\n  match_fun = list(`==`, function(a, b) abs(a - b) &lt;= tol_m)\n) %&gt;%\n  # standardise suffixes for older fuzzyjoin that uses .x/.y\n  rename_with(~ str_replace(.x, \"\\\\.x$\", \"_wh\")) %&gt;%\n  rename_with(~ str_replace(.x, \"\\\\.y$\", \"_dobih\")) %&gt;%\n  mutate(\n    height_diff = abs(height_wh - height_dobih),\n    height_diff = if_else(is.na(height_diff), Inf, height_diff)\n  )\n\n# 3) Reduce to one nearest match per row on each side, preserving FULL-join behaviour\nbest_for_left  &lt;- candidates %&gt;% group_by(row_id_x) %&gt;% slice_min(height_diff, with_ties = FALSE) %&gt;% ungroup()\nbest_for_right &lt;- candidates %&gt;% group_by(row_id_y) %&gt;% slice_min(height_diff, with_ties = FALSE) %&gt;% ungroup()\n\njoined_dat &lt;- bind_rows(best_for_left, best_for_right) %&gt;%\n  distinct(row_id_x, row_id_y, .keep_all = TRUE) %&gt;%\n  select(munro_wh, munro_dobih, \n         munro_key_wh, munro_key_dobih,\n         height_wh, height_dobih, height_diff, region,\n         xcoord:grid_ref, scramble:distance_km, ascent, spate, bog, first_route_title)%&gt;%\n  mutate(\n    site_key = coalesce(grid_ref, paste0(xcoord, \"_\", ycoord)),\n    munro_wh_clean = str_replace(munro_wh, \"\\\\s*\\\\([^)]*\\\\)$\", \"\")  # drop \"(Loch Mullardoch)\" etc.\n  ) %&gt;%\n  group_by(site_key) %&gt;%\n  slice_min(height_diff, with_ties = FALSE) %&gt;%   # keep the single closest pair for that site\n  ungroup() %&gt;%\n  mutate(munro_wh = munro_wh_clean) %&gt;%\n  select(-munro_wh_clean) |&gt;\n  mutate(time = (time_hours_min + time_hours_max) / 2) |&gt;\n  select(-munro_dobih:-munro_key_dobih) |&gt;\n  rename(munro = munro_wh)|&gt;\n  mutate(scramble_exposed = case_when(\n    scramble & exposed ~ \"Both\",\n    scramble & !exposed ~ \"Scramble\",\n    !scramble & exposed ~ \"Exposed\",\n    TRUE ~ \"Neither\"\n  )) |&gt;\n  mutate(scramble_exposed = factor(scramble_exposed,\n                                   levels = c(\"Neither\", \"Scramble\", \"Exposed\", \"Both\"))) |&gt;\n    mutate(wet = case_when(\n    spate & bog ~ \"Both\",\n    spate & !bog ~ \"Large river\",\n    !spate & bog ~ \"Boggy\",\n    TRUE ~ \"Neither\"\n  )) |&gt;\n  mutate(scramble_exposed = factor(scramble_exposed,\n                                   levels = c(\"Neither\", \"Scramble\", \"Exposed\", \"Both\")))|&gt;\n  mutate(wet = factor(wet,\n                                   levels = c(\"Neither\", \"Large river\", \"Boggy\", \"Both\")))\n\n\n\nrm(x,y, best_for_left, best_for_right, candidates, tol_m)\n\n\nI also created some manual colour scales on a nature theme:\n\n\nShow code\nnature_5 &lt;- c(\n  \"#355E3B\",  \n  \"#4B4F58\",  \n  \"#4682B4\",  \n  \"#E07B39\",\n  \"#BDB76B\"\n)\n\nnature_4 &lt;- c(\n  \"#355E3B\",  \n  \"#4B4F58\",  \n  \"#4682B4\",  \n  \"#E07B39\"   \n)\n\nnature_13 &lt;- c(\n  \"#355E3B\",  # Pine green\n  \"#6B8E23\",  # Moss\n  \"#BDB76B\",  # Dry grass\n  \"#8B5A2B\",  # Earth brown\n  \"#D2B48C\",  # Sand\n  \"#87CEEB\",  # Sky blue\n  \"#4682B4\",  # Loch blue\n  \"#191970\",  # Mountain shadow (midnight blue)\n  \"#7D7D7D\",  # Granite grey\n  \"#A9A9A9\",  # Slate grey\n  \"#8E6C88\",  # Heather purple\n  \"#E07B39\",  # Sunset orange\n  \"#FFD700\"   # Sun yellow\n)"
  },
  {
    "objectID": "post/2025-08-31-munro-tidy-tuesday/index.en.html#height-differences",
    "href": "post/2025-08-31-munro-tidy-tuesday/index.en.html#height-differences",
    "title": "Munro Tidy Tuesday",
    "section": "Height differences",
    "text": "Height differences\nNow we are cooking. First I wanted to look into the height differences between walkhighlands and Database of British and Irish Hills a little more.\n\n\nShow code\n# 1. Extract the Munros with largest discrepancies\noutliers &lt;- joined_dat %&gt;%\n  filter(height_diff &gt;3) %&gt;%\n  select(munro, height_diff) %&gt;%\n  mutate(\n    x_pos = c(2, 2, 4.5, 5.9),\n    y_pos = c(45, 75, 95, 125),  \n    y_arrow = 5                  \n  )\n\n# 2. Plot with arrows + horizontal text\nggplot(joined_dat, aes(height_diff)) +\n  geom_histogram(boundary = 0, colour = \"black\", fill = \"steelblue\") +\n  scale_x_continuous(breaks = seq(0, 8, 1)) +\n  labs(title = \"walkhighlands vs DoBIH heights\",\n       subtitle = \"wh measurements are always larger\",\n       y = \"Count\",\n       x = \"Difference in metres\") +\n  theme_minimal(base_size = 14) +\n  geom_segment(data = outliers,\n               aes(x = height_diff, xend = height_diff,\n                   y = y_arrow, yend = y_pos),\n               arrow = arrow(length = unit(0.2, \"cm\")),\n               colour = \"black\") +\n  # text labels off to the right\n  geom_text(data = outliers,\n            aes(x = x_pos, y = y_pos + 10,\n                label = munro),\n            hjust = 0, size = 4)"
  },
  {
    "objectID": "post/2025-08-31-munro-tidy-tuesday/index.en.html#scrambling-and-exposure",
    "href": "post/2025-08-31-munro-tidy-tuesday/index.en.html#scrambling-and-exposure",
    "title": "Munro Tidy Tuesday",
    "section": "Scrambling and exposure",
    "text": "Scrambling and exposure\nI have a reasonably bad fear of heights so anything that mentions scrambling or exposure worries me. First question, are higher munros scarier?\nBig thank you to Jessica Moore for the inspiration for this one.\n\n\nShow code\nggplot(joined_dat, \n       aes(height_dobih, scramble_exposed, fill = scramble_exposed)) +\n  geom_density_ridges(quantile_lines = TRUE, quantile_fun = mean,\n                      vline_linetype = \"dashed\",\n                      aes(color = \"Mean height (m)\")) +\n  scale_y_discrete(expand = c(0.01, 0)) +\n  scale_x_continuous(expand = c(0.01, 0)) +\n  scale_color_manual(values = c(\"Mean height (m)\" = \"black\")) +\n  theme_economist() +\n  scale_fill_manual(values = nature_4) +  \n  labs(x = NULL, y = NULL,\n       title = \"Are higher Munros scarier?\",\n       colour = NULL,\n       subtitle = \"Routes descriptions that mention exposure tend to be on higher Munros\")+\n  guides(fill = \"none\") +\n  theme(legend.position = \"bottom\",\n        legend.position.inside = c(0.8,0.10))\n\n\n\n\n\n\n\n\n\nFor locating the scary munros, I decided that an interactive plotly map was called for so that you can easily isolate the different types - these work much better on a full browser than a phone.\nHave I mentioned that I dislike heights and exposure?\n\n\nShow code\nmunros_map &lt;- joined_dat %&gt;%\n  select(munro, xcoord, ycoord, height_dobih, scramble_exposed, wet) %&gt;%\n  na.omit()\n\n# Convert OSGB36 coordinates to sf object\nmunros_sf &lt;- munros_map %&gt;%\n  st_as_sf(coords = c(\"xcoord\", \"ycoord\"), \n           crs = 27700)  # EPSG:27700 is OSGB36 / British National Grid\n\n# Transform to WGS84 (lat/long) for easier plotting\nmunros_lat_long &lt;- munros_sf %&gt;%\n  st_transform(crs = 4326)\n\n# Extract coordinates for ggplot\nmunros_coords &lt;- munros_lat_long %&gt;%\n  mutate(\n    longitude = st_coordinates(.)[,1],\n    latitude = st_coordinates(.)[,2]\n  ) %&gt;%\n  st_drop_geometry() %&gt;%\n  arrange(-height_dobih)\n\n\nuk_map &lt;- rnaturalearth::ne_countries(scale = \"large\", \n                                  country = \"United Kingdom\", \n                                    returnclass = \"sf\")\n\n# Step 2: Specify shape codes (16 = circle, 17 = triangle, etc.)\nshape_values &lt;- c(\n  \"Neither\" = 16,    # filled circle\n  \"Scramble\" = 17,   # filled triangle\n  \"Exposed\" = 15,    # filled square\n  \"Both\" = 18        # filled diamond\n)\n\np &lt;- ggplot() +\n  geom_sf(data = uk_map, fill = \"lightgray\", color = \"darkgrey\", size = 0.3) +\n  coord_sf(xlim = c(-8, -1.5), ylim = c(56.5, 58.6)) +\n  geom_jitter(data = munros_coords, \n             aes(x = longitude, \n                 y = latitude, \n                 shape = scramble_exposed, \n                 colour = scramble_exposed,\n                 text = munro), \n             size = 1,\n             height = .05,\n             width = .05) + \n  scale_x_continuous(breaks = NULL) +\n  scale_shape_manual(values = shape_values) +\n  scale_y_continuous(breaks = NULL) +\n  scale_colour_manual(values = nature_4) +\n  labs(title = \"Where are the scary Munros?\",\n       subtitle = \"Walk descriptions that reference:\",\n       colour = \"Route mentions\", shape = \"Route mentions\") +\n  theme_economist() +\n  theme(\n    axis.text = element_blank(),      \n    axis.ticks = element_blank(),     \n    axis.title = element_blank(),     \n    panel.grid = element_blank(),     \n    panel.border = element_blank(),\n    legend.text = element_text(size = 10)\n  )\n\nggplotly(p, tooltip = \"text\")"
  },
  {
    "objectID": "post/2025-08-31-munro-tidy-tuesday/index.en.html#by-region",
    "href": "post/2025-08-31-munro-tidy-tuesday/index.en.html#by-region",
    "title": "Munro Tidy Tuesday",
    "section": "By region",
    "text": "By region\nI also thought it would be fun to look into regional differences. The munros vary massively in character depending on where you are in the country (you can imagine hobbits living in Cairngorms whilst Skye would be home to dragons), but how is this reflected in the walk features?\nWhich region has the tallest Munros?\n\n\nShow code\nregion_height &lt;- joined_dat |&gt;\n  group_by(region) |&gt;\n  summarise(avg_height = mean(height_dobih, na.rm = TRUE), .groups = \"drop\") |&gt;\n  slice_max(avg_height, n = 5)\n\nggplot(\n  semi_join(joined_dat, region_height, by = \"region\"),\n  aes(\n    x = height_dobih,\n    y = fct_reorder(region, height_dobih, .fun = mean, .desc = FALSE),\n    fill = region\n  )\n)  +\n  geom_density_ridges(\n    quantile_lines = TRUE, quantile_fun = mean,\n    vline_linetype = \"dashed\",\n    aes(colour = \"Mean height (m)\")\n  ) +\n  scale_y_discrete(expand = c(0.01, 0)) +\n  scale_x_continuous(expand = c(0.01, 0)) +\n  scale_colour_manual(values = c(\"Mean height (m)\" = \"black\")) +\n  theme_economist() +\n  scale_fill_manual(values = nature_5) +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Which region has the highest Munros?\",\n    colour = NULL,\n    subtitle = \"Top 5 regions displayed. On average, Loch Ness has the highest Munros\"\n  ) +\n  guides(fill = \"none\") +\n  theme(\n    legend.position = \"inside\",\n   legend.position.inside = c(0.8, 0.1),\n    legend.text = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n\nWhich region has the longest walks on average by distance?\n\n\nShow code\n# Top 5 regions by mean distance\nregion_distance &lt;- joined_dat |&gt;\n  group_by(region) |&gt;\n  summarise(avg_distance = mean(distance_km, na.rm = TRUE), .groups = \"drop\") |&gt;\n  slice_max(avg_distance, n = 5)\n\n# Keep only those regions in the raw data\ntop_dat &lt;- semi_join(joined_dat, region_distance, by = \"region\")\n\n\nggplot(\n  top_dat,\n  aes(\n    x = distance_km,  # use the per-route variable here\n    y = fct_reorder(region, distance_km, .fun = mean, .desc = FALSE),\n    fill = region\n  )\n) +\n  geom_density_ridges(\n    quantile_lines = TRUE, quantile_fun = mean,\n    vline_linetype = \"dashed\",\n    aes(colour = \"Mean distance (km)\")\n  ) +\n  scale_y_discrete(expand = c(0.01, 0)) +\n  scale_x_continuous(expand = c(0.01, 0)) +\n  scale_colour_manual(values = c(\"Mean distance (km)\" = \"black\")) +\n  theme_economist() +\n  scale_fill_manual(values = nature_5) +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Which region has the longest walks?\",\n    colour = NULL,\n    subtitle = \"Top 5 regions displayed. On average, Loch Ness has the longest walks\"\n  ) +\n  guides(fill = \"none\") +\n  theme(\n    legend.position = \"inside\",\n    legend.position.inside = c(0.82, .1),\n    legend.text = element_text(size = 10)\n    )\n\n\n\n\n\n\n\n\n\nWhich region has the most ascent?\n\n\nShow code\n# Top 5 regions by mean distance\nregion_ascent &lt;- joined_dat |&gt;\n  group_by(region) |&gt;\n  summarise(avg_ascent = mean(ascent, na.rm = TRUE), .groups = \"drop\") |&gt;\n  slice_max(avg_ascent, n = 5)\n\n# Keep only those regions in the raw data\ntop_ascent &lt;- semi_join(joined_dat, region_ascent, by = \"region\")\n\n\nggplot(\n  top_ascent,\n  aes(\n    x = ascent,  # use the per-route variable here\n    y = fct_reorder(region, ascent, .fun = mean, .desc = FALSE),\n    fill = region\n  )\n) +\n  geom_density_ridges(\n    quantile_lines = TRUE, quantile_fun = mean,\n    vline_linetype = \"dashed\",\n    aes(colour = \"Mean ascent (m)\")\n  ) +\n  scale_y_discrete(expand = c(0.01, 0)) +\n  scale_x_continuous(expand = c(0.01, 0)) +\n  scale_colour_manual(values = c(\"Mean ascent (m)\" = \"black\")) +\n  theme_economist() +\n  scale_fill_manual(values = nature_5) +\n  labs(\n    x = NULL, y = NULL,\n    title = \"Which region has the most ascent?\",\n    colour = NULL,\n    subtitle = \"Top 5 regions displayed. On average, Loch Ness has the most ascent\"\n  ) +\n  guides(fill = \"none\") +\n  theme(\n    legend.position = \"inside\",\n    legend.position.inside = c(0.82, .1),\n    legend.text = element_text(size = 10)  \n    )\n\n\n\n\n\n\n\n\n\nAnd finally, where do you get the most bang for your buck?\nUllapool\n\n\nShow code\njoined_dat |&gt;\n  count(region, first_route_title, name = \"n\") |&gt;\n  group_by(region) |&gt;\n  summarise(avg_count = mean(n), .groups = \"drop\") |&gt;\n  ggplot(aes(\n    x = fct_reorder(region, avg_count),\n    y = avg_count,\n    fill = region\n  )) +\n  geom_col() +\n  scale_fill_manual(values = nature_13) +\n  coord_flip() +\n  guides(fill = \"none\") +\n  labs(x = NULL, y = \"Number of Munros\",\n       title = \"Average number of Munros bagged per route\") +\n  theme_economist()"
  },
  {
    "objectID": "post/2025-08-31-munro-tidy-tuesday/index.en.html#ascent",
    "href": "post/2025-08-31-munro-tidy-tuesday/index.en.html#ascent",
    "title": "Munro Tidy Tuesday",
    "section": "Ascent",
    "text": "Ascent\nAs you would expect, total ascent correlates strongly with total time, but there are some points of interest. Bidein a’ Choire Sheasgaich and Lurg Mhòr have the longest estimated walk time but their remoteness means that they’re an outlier in terms of the amount of ascent you’d expect for that time. The Fisherfield 6 claim the prize for most ascent by some distance but are bang on in terms of the ascent/time relationship. Meall Buidhe wins the award for being the quickest munro to bag, with the least ascent.\n\n\nShow code\nggplot(joined_dat, aes(x = ascent, y = time)) +\n  geom_jitter(height = .05, width = .05) +\n  scale_x_continuous(breaks = seq(500, 2500, 250)) +\n  scale_y_continuous(breaks = seq(0, 20, 2)) +\n  annotate(geom = \"curve\", \n          x = 1200, y = 15, \n          xend = 1450, yend = 16,\n          curvature = -0.3,\n          arrow = arrow(length = unit(0.5, \"lines\"))) +\n    annotate(\"text\",\n           x = 1150, y = 14.5,\n           label = \"Bidein a' Choire Sheasgaich\\nand Lurg Mhòr\") +\n    annotate(geom = \"curve\", \n          x = 2050, y = 13.5, \n          xend = 2220, yend = 15,\n          curvature = -0.3,\n          arrow = arrow(length = unit(0.5, \"lines\"))) +\n    annotate(\"text\",\n           x = 2100, y = 13,\n           label = \"Fisherfield 6\")+\n    annotate(geom = \"curve\", \n          xend = 575, yend = 2.9, \n          x = 1250, y = 4,\n          curvature = 0.2,\n          arrow = arrow(length = unit(0.5, \"lines\"))) +\n    annotate(\"text\",\n           x = 1450, y = 4.5,\n           label = \"Meall Buidhe\")+\n  theme_economist()  +\n  labs(x = \"Ascent (m)\", \n       y = \"Time (hours)\",\n       title = \"Total ascent by time\") +\n    theme(legend.position = \"inside\",\n    axis.title.x = element_text(margin = margin(t = 8)),\n    axis.title.y = element_text(margin = margin(r = 8)),\n    legend.position.inside = c(0.9, .2),\n    legend.text = element_text(size = 10)  \n  )\n\n\n\n\n\n\n\n\n\nAnd here’s an interactive version of that plot that adds in scrambling and exposure because had I mentioned, I am scared of heights.\n\n\nShow code\np1 &lt;- ggplot(joined_dat, aes(x = ascent, y = time)) +\n  geom_jitter(aes(shape = scramble_exposed, \n                 colour = scramble_exposed,\n                 text = munro), \n             size = 1, width = .1, height = .1) +\n  scale_x_continuous(breaks = seq(500,2500, 250)) +\n  scale_y_continuous(breaks = seq(0,20,2)) +\n  scale_shape_manual(values = shape_values) +\n  scale_colour_manual(values= nature_4) +\n  labs(x = \"Ascent (m)\", \n       y = \"Time (hours)\",\n       title = \"Ascent by time\",\n       shape = \"Route mentions\",\n       colour = \"Route mentions\") +\n  theme_economist() +\n  theme(\n    axis.title.x = element_text(margin = margin(t = 8)),\n    axis.title.y = element_text(margin = margin(r = 8)),\n    legend.text = element_text(size = 10)\n  )\n\nggplotly(p1, tooltip = \"text\")"
  },
  {
    "objectID": "post/2025-08-31-munro-tidy-tuesday/index.en.html#wheres-wet",
    "href": "post/2025-08-31-munro-tidy-tuesday/index.en.html#wheres-wet",
    "title": "Munro Tidy Tuesday",
    "section": "Where’s wet?",
    "text": "Where’s wet?\nIf the text-mining for scrambling and exposure is a blunt tool then my approach here is even blunter. There are multiple words I could have searched for regarding the presence of water - river, stream, burn - but many of those represent features that don’t make a difference to the walk if they present no difficulty (“cross the bridge over the river”). I decided to use the word “spate” because when the river is large, walkhighlands often highlights that it would be difficult or impossible to cross “in spate”.\nSo these aren’t all the rivers, just ones where the description indicates crossing them might present an issue.\n\n\nShow code\nshape_values &lt;- c(\n  \"Neither\" = 16,    # filled circle\n  \"River\" = 17,   # filled triangle\n  \"Boggy\" = 15,    # filled square\n  \"Both\" = 18        # filled diamond\n)\n\np2 &lt;- ggplot() +\n  geom_sf(data = uk_map, fill = \"lightgray\", color = \"darkgrey\", size = 0.3) +\n  coord_sf(xlim = c(-8, -1.5), ylim = c(56.5, 58.6)) +\n  geom_jitter(data = munros_coords, \n             aes(x = longitude, \n                 y = latitude, \n                 shape = wet, \n                 colour = wet,\n                 text = munro), \n             size = 1,\n             height = .05,\n             width = .05) + \n  scale_x_continuous(breaks = NULL) +\n  scale_shape_manual(values = shape_values) +\n  scale_y_continuous(breaks = NULL) +\n  scale_colour_manual(values = nature_4) +\n  guides(shape = \"none\") +\n  labs(title = \"Where is wet?\\n(Everywhere, it's Scotland)\",\n              subtitle = \"Walk descriptions that reference:\",\n       colour = \"Route mentions\", shape = \"Route mentions\") +\n  theme_economist() +\n  theme(\n    axis.text = element_blank(),      \n    axis.ticks = element_blank(),     \n    axis.title = element_blank(),     \n    panel.grid = element_blank(),     \n    panel.border = element_blank(),\n    legend.text = element_text(size = 10)\n  )\n\nggplotly(p2, tooltip = \"text\")\n\n\n\n\n\n\nI may have become a bit obsessed.\nI must stop.\nBut if you have any other suggestions for analysis….just ask."
  },
  {
    "objectID": "post/2024-10-26-mcqs-in-the-age-of-ai/index.en.html",
    "href": "post/2024-10-26-mcqs-in-the-age-of-ai/index.en.html",
    "title": "MCQs in the age of AI",
    "section": "",
    "text": "I shared this guide on Writing Good Multiple Choice Test Questions on social media and the first response I got on both LinkedIn and BlueSky was whether MCQs hold up in the age of AI. As first year lead for many years, this is a problem I’ve put a huge amount of thought into, so if you’re interested in all those thoughts, buckle up.\nI am assuming that the long-form version of the question “do MCQs hold up in the age of AI?” is really “does the academic integrity of online open-book MCQs hold up in the age of AI?” And the answer to that question is quite categorically no but let me take a little detour about what we did when we moved online for covid because it also serves as a defence of MCQs, which is honestly the real point of this post.\n\nHigh stakes MCQ exams\nIn 2020, our Level 1 exam was an 80-question MCQ exam that students had 60 minutes to complete. It was worth 40% of their final course grade, with the rest coming from an essay and an engagement portfolio of low-stakes data skills, weekly quizzes, and research participation. In the first semester of 2020, we ran the exam online using much the same questions that we’d used when the exam was in-person and it was a disaster. The distribution that had held for years crumbled. The average grade was a high A.\nNow before anyone calls me a demon for decrying students performing well, I’ve got no issue with assessments where the grades skew high because they’ve all learned a lot and studied hard, but this was not that. The issue was that we’d given them factual MCQs that could be easily Googled, for example:\n\nWhich of the following best describes a between-subjects design in experimental research?\n\nThe same participants take part in all conditions of the experiment.\nDifferent groups of participants experience only one condition each.\nParticipants are observed in their natural environment without intervention.\nThe experiment includes both repeated measures and independent groups.\n\n\nSo we burned down the exam questions and started again. I’m continually amazed by my team, they’re wonderful people who are truly excellent at their jobs and care deeply about learning and teaching and I can’t over-estimate the work they put into this. We consulted the literature on best practice for MCQs (Blake Harvard has a great blog about how to make more effective MCQs) and rewrote all the questions to require students to apply their knowledge and, crucially, questions that could not be easily answered by Google at the time. For example, the above factual MCQ became the below applied MCQ:\n\nA researcher designs an experiment where participants either drink caffeinated coffee or decaffeinated coffee and then take part in a reaction time test. Based on the information provided, what is the design of this experiment?\n\nBetween -subjects\nWithin-subjects\nMixed-design\nCase study\n\n\nThe distribution returned to a peak of a low to middling B / 2:1 but more than that, I think we created a much, much better exam, one that measured their knowledge and their ability to apply it, rather than their memory. They could have all their notes with them but if they hadn’t put in the time to understand what they were being taught, it wouldn’t help much. One of my key frustrations with the discussion over exams is the default assumption that they are all bad. Let’s say it again for the people are the back “EXAMS ARE NOT BAD, BAD EXAMS ARE BAD”. You give students a 100% closed book exam that only tests how well they can remember a bunch of names and dates, with no thought to accessibility, and little in the way of learning support throughout the semester, then sure, exams are shit.\nBut rote memorisation is not the same as knowledge. And students need knowledge. You can’t critically evaluate something you don’t know. There is a very robust literature on the impact of prior knowledge on learning new knowledge and skills and for many introductory courses (like first year psychology), building that knowledge base so that they can go on and do more interesting things is the point. Please stop asking me if I’d like to replace my first year exam with a podcast or experiential learning. I am happy to die on the hill that a) “authentic assessment” as a response to every question about assessment and feedback has become a hollow, meaningless slogan for people without true expertise in effective learning and teaching (see also, active learning) and b) having a broad knowledge base of psychological concepts and theories is an authentic part of being a psychologist.\nAnd this is actually my main concern when it comes to AI. Yes academic integrity is important but for me, the fact that they won’t learn anything is what keeps me up at night. If there was some way they could use AI to cheat but still have developed all that core knowledge then I would honestly care less. But what I’ve seen over the last few years is a slow creep of students who are unable to tackle those more interesting tasks of analysing, evaluating, and creating, because either they, or their education system, skipped over developing core knowledge. There is also unquestionably a workload component to MCQ exams as well. I have 600-700 students on my course each year and they provide an effective and efficient method of testing their knowledge acquisition. That’s important.\nWhat was the point of this blog post again? Oh right. If you have a high stakes summative open-book MCQ exam, it needs to go back in person, rather than in the bin. Whether it’s susceptible to AI is an entirely different discussion to whether it’s still a useful assessment.\n\n\nLow stakes MCQs\nYou might think I’ve written enough but I also want to discuss the issue of low-stakes MCQs, because we’ve done a lot of work on those as well.\nIn our first semester Level 1 course, we had two types of low-stakes MCQs. First, there were weekly MCQs that were related to the lecture content and these were originally a mark for participation (5% in total) because there’s also a robust literature on the impact of practice testing and distributed practice on learning and the quizzes supported students to study continuously. Second, we had an open-book MCQ about data skills and programming in R that was worth 5% of their grade and arrived in week 6 of term. Pre-AI, this MCQ was very, very effective at identifying students who had been keeping up with their data skills work and those who had disengaged / were trying to cram. Post-AI, pointless.\nBut again, the issue here isn’t academic integrity. These are low-stakes assessments where we expected the grades to skew high. I don’t care if they all get As, I care if they’re learning. So our response has been to change the grading scheme rather than the MCQs themselves. This year, students get two attempts at each MCQ (I must acknowledge that I stole this idea from Dr. Carolina Kuepper-Tetzel, Learning Scientist and all-round excellent work wife). On the first attempt, they’re instructed to not use any notes and instead use it as a pure test of their knowledge. After the first attempt, they see which ones they got right and wrong and then on the second attempt, they can use whatever they want to improve their score.\nBy doing this, they still get the boost that comes from practice testing and they also get feedback on how their learning is progressing. But the second attempt means that they get the grade and again, it’s low-stakes and the assessment load of the course has been built to withstand a high skew on these components.\nMore importantly, I hope that what we’re doing is implicitly and explicitly teaching students about effective study strategies and the difference between assessment for learning and assessment for grades and that we’re targeting motivation rather than just banging on about misconduct. Of course, students could still use AI to complete the first attempt but particularly when it comes to the data skills MCQ, it’s going to be very easy to identify them in the first-attempt distribution (very few used to get full-marks on that test). I’m not going to use this as some sort of integrity test (see again: not a demon) but I can use it to make the point that if these grades are your own work, this is amazing, but if they represent the use of AI, here’s why you’re only hurting yourself."
  }
]
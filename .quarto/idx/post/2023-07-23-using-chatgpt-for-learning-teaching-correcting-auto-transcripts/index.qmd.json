{"title":"Using ChatGPT for learning & teaching: Correcting auto-transcripts","markdown":{"yaml":{"title":"Using ChatGPT for learning & teaching: Correcting auto-transcripts","author":"Emily Nordmann","date":"2023-07-23","slug":"using-chatgpt-for-learning-teaching-correcting-auto-transcripts"},"headingText":"Correcting transcripts","containsRefs":false,"markdown":"\n\nAlongside Wil Tovio and Rachel O'Neill, I've written before in the\n[Times\nHigher](https://www.timeshighereducation.com/campus/new-rules-lecture-transcripts-give-academics-impossible-choice)\nabout the problems that requiring academics to produce corrected\ncaptions introduces. If you don't do it, you disadvantage a wide range\nof students and effectively ruin the education of those who are d/Deaf\nand hard-of-hearing. If you do, you put a much higher workload burden on\nany lecturer with a \"non-standard\" accent, those with poorer quality\nrecording equipment, and let's honest, those who just care a bit more. I\nsay all of this whilst recognising my own privilege: most recording\nsoftware generally picks up what I am saying accurately and through both\nwork and personal means, I invested in a high-quality mic at the start\nof covid.\n\n\nBut anyway. It just occurred to me that one use of ChatGPT that falls\nunder the category \"let's make the admin associated with teaching\neasier\" is that we might be able to use it to edit transcriptions for\nus. And for once, I actually have the means to evaluate how it's done in\nthe form of an original automated-transcription, the corrected version a\nhuman spent hours on, and the audio. The video in question was a\nwalkthrough of a data skills tutorial in R, and platforms like Zoom and\nEcho360 tend to struggle with the technical terminology.\n\nI downloaded the original transcript as a .txt file from Echo360 and put\nthe following prompt into ChatGPT. I've got a paid subscription and\naccess to GPT4.0 but I chose to use GPT3.5 as that's the one most people\nhave access to.\n\n> Act like an expert in the programming language R. I have recorded a\n> lecture which is a walkthrough video of a tutorial in R. The learning\n> outcomes are: Be able to reshape data between long and wide formats;\n> Separate, change, reorder, and rename columns; Use pipes to chain\n> together functions. Recording software has automatically transcribed\n> the recording but there are many errors. Below is the transcript,\n> correct the transcription errors.\n\nThe full transcript is much longer than ChatGPT can take in one response\nso you either have to do it bit by bit, or tell it you're going to split\nthe document and not to proceed until you tell it you're finished. For\nthe purposes of this tutorial, I just copied and pasted what I thought\nwould fit.\n\nOnce it produced the corrected transcript I then asked:\n\n> Tell me what you changed and give me the original and the corrected\n> version so I can easily compare them.\n\nIt gave me a list of 7 changes it had made, I won't list them all but\nhow did it do?\n\n-   **Original**: \"So now that we have looked that in and will open up a\n    new a junk...\"\\\n-   **Corrected by ChatGPT:** \"So now that we have loaded that in, let's\n    open up a new chunk...\"\\\n-   **Corrected by human:** \"So now that we have locked that in, I will\n    open up a new a chunk\"\n\nListening to the audio, you could sensibly conclude it was either\n\"loaded\" or \"locked\", (the human doing the editing wasn't the human\ndoing the lecture) and both make sense in context. For the second part\nof the sentence, the audio is a bit disfluent, both the human and\nChatGPT have corrected it to what was clearer the intent of the sentence\nand whilst they're different, they both work.\n\n-   **Original**: \"Let's compare this to a version of this table, but in\n    completely tiny format\"\n-   **Corrected by ChatGPT**: \"Let's compare this to a version of this\n    table but in a completely tidy format\"\\\n-   **Corrected by human:** \"Let's compare this to a version of this\n    table, but in completely tidy format.\"\n\nChatGPT and the human produced the same correction.\n\n-   **Original**:\"...we now have three columns here where each column is\n    its own variable one just four items, one just for the price per\n    item and one just for the total price, and they are distinguished by\n    this for scoring here.\"\\\n-   **Corrected by ChatGPT**: \"...we now have three columns here: one\n    just for items, one just for the price per item, and one just for\n    the total price, and they are distinguished by this 'year' column.\"\\\n-   **Corrected by human:** \"we now have three columns here where each\n    column is its own variable one just for items, one just for the\n    price per item and one just for the total price, and they are\n    distinguished by this fourth column here - year.\n\nChatGPT has removed a few words \"here each column is its own variable\"\nwhich in this case doesn't really affect the overall meaning in the\ncontext of the wider section but if it's going to do that you'd want to\nmake sure you're checking each correction.\n\n## The whole truth and nothing but the truth\n\nWhilst it gave me 7 corrections, I could see that it had made more than\nthe initial list it gave so I followed up:\n\n> These aren't all the changes, tell me everything you changed\n\nAnd it then produced a list of 18 changes, apologising for the\noversight. So I probed further:\n\n> Is this a complete list of all changes now or are there more?\n\nIt then gave me an additional extra change. Hmmm. The text file dumps\nthe transcription into one big block of text, but Echo360 also gives the\noption to download the .VTT file that has it line-by-line with\ntime-stamps e.g.:\n\n> 00:00:21.110 --\\> 00:00:24.680 \\<v Speaker 0\\>So as usual, we're going\n> to start off by creating\n\n> NOTE CONF {\"raw\":[100,100,100,52,93,100,100,100,100,100]} 00:00:24.680\n> --\\> 00:00:27.860 \\<v Speaker 0\\>a new project for this chapter so\n> that we can\n\n> NOTE CONF {\"raw\":[100,100,94,100,100,100,100,100,100,100]}\n> 00:00:27.860 --\\> 00:00:29.570 \\<v Speaker 0\\>work through things\n> together.\n\nI thought that maybe chunking the text a bit would help it be able to\nidentify the changes but all it did was render the correction completely\nuseless. Splitting up the text with the time stamps appears to stop it\nbeing able to parse it properly which is interesting in a way that makes\nme realise I've got no idea what's going on under the hood.\n\n## No single truth\n\nMy internet acted up and I couldn't access the chat I was having for\nthis blog so I redid the prompt in a new chat, with the same prompt and\nsection of the script.\n\nThis time it gave me 33 changes. Some of them were the same, some of\nthem were different. Which is not surprising because that's how ChatGPT\nworks, it's all prediction and you can use the regenerate response\noption to get a slightly different version if you're not happy with\nwhatever it has produced. But in the context of transcription, it's a\nreally useful reminder that it isn't \"correcting\" it, it's doing what it\nnormally does which is predicting what word should come next. It doesn't\nhave the source audio, it's not doing what an underpaid human would be\ndoing.\n\nIt's possible that had I initially asked it \"give me a complete list of\nall changes, leave nothing out\", it wouldn't have missed any. But also,\nit is well-known that you can \"trick\" ChatGPT into thinking it's wrong\njust by telling it that it is:\n\n![](images/Screenshot%202023-07-23%20172451.png)\n\nSo it could be that my follow-up prompts insisting it had missed\nsomething resulted in it making up new prompts to satisfy the monkey at\nits typewriter. In a nutshell, you can't use ChatGPT to verify what\nChatGPT has produced. The snake will eat its own tail.\n\nMore worryingly, in additional attempts both with 3.5 and GPT4.0, it\nstarted editing more than you'd want for a transcription correction. For\nexample:\n\n> Before we go any further here, I'm going to to switch to year. As you\n> can see, we're going to switch to this year. So hopefully you are now\n> seeing my internet browser,\n\nConsulting the audio, this should be \"I'm going to switch to share, as\nyou can see, I'm going to switch to this here. So hopefully you are now\nseeing my internet browser\". It's not a sentence that makes a great deal\nof sense without the video (which is describing changing what is being\nshared on the screen) but that's what you'd want the transcript to say\nbecause alongside the video it does make sense.\n\nThis is what ChatGPT changed it to:\n\n> Before we delve deeper, I'm going to switch screens. You should now\n> see my internet browser.\n\nWhich makes a lot more sense except for the fact it doesn't actually\nrepresent what was said.\n\n## Maybe we're asking the wrong questions\n\nThis feels like a task ChatGPT should be able to perform so I became\nslightly obsessed and starting trying different prompts, convinced that\nmaybe the issue was that I wasn't being specific enough:\n\n> Act like a video editor who is an expert in the programming language R\n> who has been asked to correct a transcript for the subtitles of a\n> recorded lecture which is a walkthrough video of a tutorial in R.\n\n> The learning outcomes are: Be able to reshape data between long and\n> wide formats; Separate, change, reorder, and rename columns; Use pipes\n> to chain together functions.\n\n> Recording software has automatically transcribed the recording but\n> there are many errors where the transcription software has not\n> accurately assessed what word has been said. Below is the transcript,\n> edit all words that are likely to be transcription errors so that they\n> can be used as subtitles. Do not edit anything that is not likely to\n> be an error and do not paraphrase or change the meaning.\n\nThis seemed to keep to the brief of not changing the meaning a lot\nbetter although it was perhaps a little too conservative (but if the\noption is change too much or too little, perhaps that's for the best).\nAdditionally it didn't get everything right (e.g., 2 and 4 aren't right\nbut I suppose they're no more wrong than the original automated\ntranscript so it is at least not changing things that aren't wrong).\n\n![](images/Screenshot%202023-07-24%20083018.png)\n\n## Is this any use?\n\nThe question is then, given all these issues, is this any use? The edits\nit produced on my first attempt were really very impressive and reading\nthrough the edited transcript, it all made sense and I was getting very\nexcited. But as I kept going I got more and more cautious. In some cases\nit's not necessarily problematic that it wasn't a one-to-one correction,\nthe human also made some choices that deviated from an exact script to\nmake it make sense, but without a lot of work on the prompt in some\ncases ChatGPT was paraphrasing way beyond the original intent and\nmeaning. I was forced to remind myself that it's not \"correcting\" words\nand it doesn't have access to the audio. Additionally, it's very\ndifficult to get it to tell you everything it changed so you absolutely\ncouldn't use this without verifying it.\n\nOn my first attempt, the amount it got right would hugely cut-down on\nthe time it takes to correct a transcript and a more specific prompt\nseemed to solve some of the issues with paraphrasing. It was certainly\nstill better than the automated transcript, so one possible option could\nbe to take the original, run it through ChatGPT, and then get a human to\ncorrect the ChatGPT version. That way, you make the workload more\nmanageable, but you still have human eyes on it.\n\nI think whether or not it is worth it probably depends on how much\ntranscription you have to do. If you have hours and hours of recorded\ncontent to transcribe then it is probably worth training ChatGPT to do\nexactly what you want and to take the time to build the prompts and find\na balance you're happy with because in the long-run it will still save\nhuge amounts of time. However, if I had a single video, I'm not sure I\nwould currently bother as it probably takes enough work to get it right\nthan it does just to do it manually.\n\nThis blog feels like a stream-of-consciousness but what this process has\ndone is change the way I would approach using ChatGPT to edit anything.\nI'm currently working on guidance for essay writing for students and I\nthink my experience here has taught me that I wouldn't ask it to edit\nanything directly but instead to give suggestions alongside the\noriginal. For the purposes of transcription correction, that process\nmakes it time-consuming but for an essay or any other piece of writing,\nit would ensure you're making active choices.\n\nAnother consideration is privacy. If you upload your transcripts, you're\nessentially giving OpenAI your lecture to help train its LLM [unless you\nchange the default\nsettings](https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt).\nWhether you care about that is up to you, but make a conscious choice.\n\nAnd finally, none of this changes the fact that the problem with the\nworkload involved with transcription will still be higher for people\nworking in their second language and those who have regional accents and\nthat academic workload modelling is a complete joke.\n","srcMarkdownNoYaml":"\n\nAlongside Wil Tovio and Rachel O'Neill, I've written before in the\n[Times\nHigher](https://www.timeshighereducation.com/campus/new-rules-lecture-transcripts-give-academics-impossible-choice)\nabout the problems that requiring academics to produce corrected\ncaptions introduces. If you don't do it, you disadvantage a wide range\nof students and effectively ruin the education of those who are d/Deaf\nand hard-of-hearing. If you do, you put a much higher workload burden on\nany lecturer with a \"non-standard\" accent, those with poorer quality\nrecording equipment, and let's honest, those who just care a bit more. I\nsay all of this whilst recognising my own privilege: most recording\nsoftware generally picks up what I am saying accurately and through both\nwork and personal means, I invested in a high-quality mic at the start\nof covid.\n\n## Correcting transcripts\n\nBut anyway. It just occurred to me that one use of ChatGPT that falls\nunder the category \"let's make the admin associated with teaching\neasier\" is that we might be able to use it to edit transcriptions for\nus. And for once, I actually have the means to evaluate how it's done in\nthe form of an original automated-transcription, the corrected version a\nhuman spent hours on, and the audio. The video in question was a\nwalkthrough of a data skills tutorial in R, and platforms like Zoom and\nEcho360 tend to struggle with the technical terminology.\n\nI downloaded the original transcript as a .txt file from Echo360 and put\nthe following prompt into ChatGPT. I've got a paid subscription and\naccess to GPT4.0 but I chose to use GPT3.5 as that's the one most people\nhave access to.\n\n> Act like an expert in the programming language R. I have recorded a\n> lecture which is a walkthrough video of a tutorial in R. The learning\n> outcomes are: Be able to reshape data between long and wide formats;\n> Separate, change, reorder, and rename columns; Use pipes to chain\n> together functions. Recording software has automatically transcribed\n> the recording but there are many errors. Below is the transcript,\n> correct the transcription errors.\n\nThe full transcript is much longer than ChatGPT can take in one response\nso you either have to do it bit by bit, or tell it you're going to split\nthe document and not to proceed until you tell it you're finished. For\nthe purposes of this tutorial, I just copied and pasted what I thought\nwould fit.\n\nOnce it produced the corrected transcript I then asked:\n\n> Tell me what you changed and give me the original and the corrected\n> version so I can easily compare them.\n\nIt gave me a list of 7 changes it had made, I won't list them all but\nhow did it do?\n\n-   **Original**: \"So now that we have looked that in and will open up a\n    new a junk...\"\\\n-   **Corrected by ChatGPT:** \"So now that we have loaded that in, let's\n    open up a new chunk...\"\\\n-   **Corrected by human:** \"So now that we have locked that in, I will\n    open up a new a chunk\"\n\nListening to the audio, you could sensibly conclude it was either\n\"loaded\" or \"locked\", (the human doing the editing wasn't the human\ndoing the lecture) and both make sense in context. For the second part\nof the sentence, the audio is a bit disfluent, both the human and\nChatGPT have corrected it to what was clearer the intent of the sentence\nand whilst they're different, they both work.\n\n-   **Original**: \"Let's compare this to a version of this table, but in\n    completely tiny format\"\n-   **Corrected by ChatGPT**: \"Let's compare this to a version of this\n    table but in a completely tidy format\"\\\n-   **Corrected by human:** \"Let's compare this to a version of this\n    table, but in completely tidy format.\"\n\nChatGPT and the human produced the same correction.\n\n-   **Original**:\"...we now have three columns here where each column is\n    its own variable one just four items, one just for the price per\n    item and one just for the total price, and they are distinguished by\n    this for scoring here.\"\\\n-   **Corrected by ChatGPT**: \"...we now have three columns here: one\n    just for items, one just for the price per item, and one just for\n    the total price, and they are distinguished by this 'year' column.\"\\\n-   **Corrected by human:** \"we now have three columns here where each\n    column is its own variable one just for items, one just for the\n    price per item and one just for the total price, and they are\n    distinguished by this fourth column here - year.\n\nChatGPT has removed a few words \"here each column is its own variable\"\nwhich in this case doesn't really affect the overall meaning in the\ncontext of the wider section but if it's going to do that you'd want to\nmake sure you're checking each correction.\n\n## The whole truth and nothing but the truth\n\nWhilst it gave me 7 corrections, I could see that it had made more than\nthe initial list it gave so I followed up:\n\n> These aren't all the changes, tell me everything you changed\n\nAnd it then produced a list of 18 changes, apologising for the\noversight. So I probed further:\n\n> Is this a complete list of all changes now or are there more?\n\nIt then gave me an additional extra change. Hmmm. The text file dumps\nthe transcription into one big block of text, but Echo360 also gives the\noption to download the .VTT file that has it line-by-line with\ntime-stamps e.g.:\n\n> 00:00:21.110 --\\> 00:00:24.680 \\<v Speaker 0\\>So as usual, we're going\n> to start off by creating\n\n> NOTE CONF {\"raw\":[100,100,100,52,93,100,100,100,100,100]} 00:00:24.680\n> --\\> 00:00:27.860 \\<v Speaker 0\\>a new project for this chapter so\n> that we can\n\n> NOTE CONF {\"raw\":[100,100,94,100,100,100,100,100,100,100]}\n> 00:00:27.860 --\\> 00:00:29.570 \\<v Speaker 0\\>work through things\n> together.\n\nI thought that maybe chunking the text a bit would help it be able to\nidentify the changes but all it did was render the correction completely\nuseless. Splitting up the text with the time stamps appears to stop it\nbeing able to parse it properly which is interesting in a way that makes\nme realise I've got no idea what's going on under the hood.\n\n## No single truth\n\nMy internet acted up and I couldn't access the chat I was having for\nthis blog so I redid the prompt in a new chat, with the same prompt and\nsection of the script.\n\nThis time it gave me 33 changes. Some of them were the same, some of\nthem were different. Which is not surprising because that's how ChatGPT\nworks, it's all prediction and you can use the regenerate response\noption to get a slightly different version if you're not happy with\nwhatever it has produced. But in the context of transcription, it's a\nreally useful reminder that it isn't \"correcting\" it, it's doing what it\nnormally does which is predicting what word should come next. It doesn't\nhave the source audio, it's not doing what an underpaid human would be\ndoing.\n\nIt's possible that had I initially asked it \"give me a complete list of\nall changes, leave nothing out\", it wouldn't have missed any. But also,\nit is well-known that you can \"trick\" ChatGPT into thinking it's wrong\njust by telling it that it is:\n\n![](images/Screenshot%202023-07-23%20172451.png)\n\nSo it could be that my follow-up prompts insisting it had missed\nsomething resulted in it making up new prompts to satisfy the monkey at\nits typewriter. In a nutshell, you can't use ChatGPT to verify what\nChatGPT has produced. The snake will eat its own tail.\n\nMore worryingly, in additional attempts both with 3.5 and GPT4.0, it\nstarted editing more than you'd want for a transcription correction. For\nexample:\n\n> Before we go any further here, I'm going to to switch to year. As you\n> can see, we're going to switch to this year. So hopefully you are now\n> seeing my internet browser,\n\nConsulting the audio, this should be \"I'm going to switch to share, as\nyou can see, I'm going to switch to this here. So hopefully you are now\nseeing my internet browser\". It's not a sentence that makes a great deal\nof sense without the video (which is describing changing what is being\nshared on the screen) but that's what you'd want the transcript to say\nbecause alongside the video it does make sense.\n\nThis is what ChatGPT changed it to:\n\n> Before we delve deeper, I'm going to switch screens. You should now\n> see my internet browser.\n\nWhich makes a lot more sense except for the fact it doesn't actually\nrepresent what was said.\n\n## Maybe we're asking the wrong questions\n\nThis feels like a task ChatGPT should be able to perform so I became\nslightly obsessed and starting trying different prompts, convinced that\nmaybe the issue was that I wasn't being specific enough:\n\n> Act like a video editor who is an expert in the programming language R\n> who has been asked to correct a transcript for the subtitles of a\n> recorded lecture which is a walkthrough video of a tutorial in R.\n\n> The learning outcomes are: Be able to reshape data between long and\n> wide formats; Separate, change, reorder, and rename columns; Use pipes\n> to chain together functions.\n\n> Recording software has automatically transcribed the recording but\n> there are many errors where the transcription software has not\n> accurately assessed what word has been said. Below is the transcript,\n> edit all words that are likely to be transcription errors so that they\n> can be used as subtitles. Do not edit anything that is not likely to\n> be an error and do not paraphrase or change the meaning.\n\nThis seemed to keep to the brief of not changing the meaning a lot\nbetter although it was perhaps a little too conservative (but if the\noption is change too much or too little, perhaps that's for the best).\nAdditionally it didn't get everything right (e.g., 2 and 4 aren't right\nbut I suppose they're no more wrong than the original automated\ntranscript so it is at least not changing things that aren't wrong).\n\n![](images/Screenshot%202023-07-24%20083018.png)\n\n## Is this any use?\n\nThe question is then, given all these issues, is this any use? The edits\nit produced on my first attempt were really very impressive and reading\nthrough the edited transcript, it all made sense and I was getting very\nexcited. But as I kept going I got more and more cautious. In some cases\nit's not necessarily problematic that it wasn't a one-to-one correction,\nthe human also made some choices that deviated from an exact script to\nmake it make sense, but without a lot of work on the prompt in some\ncases ChatGPT was paraphrasing way beyond the original intent and\nmeaning. I was forced to remind myself that it's not \"correcting\" words\nand it doesn't have access to the audio. Additionally, it's very\ndifficult to get it to tell you everything it changed so you absolutely\ncouldn't use this without verifying it.\n\nOn my first attempt, the amount it got right would hugely cut-down on\nthe time it takes to correct a transcript and a more specific prompt\nseemed to solve some of the issues with paraphrasing. It was certainly\nstill better than the automated transcript, so one possible option could\nbe to take the original, run it through ChatGPT, and then get a human to\ncorrect the ChatGPT version. That way, you make the workload more\nmanageable, but you still have human eyes on it.\n\nI think whether or not it is worth it probably depends on how much\ntranscription you have to do. If you have hours and hours of recorded\ncontent to transcribe then it is probably worth training ChatGPT to do\nexactly what you want and to take the time to build the prompts and find\na balance you're happy with because in the long-run it will still save\nhuge amounts of time. However, if I had a single video, I'm not sure I\nwould currently bother as it probably takes enough work to get it right\nthan it does just to do it manually.\n\nThis blog feels like a stream-of-consciousness but what this process has\ndone is change the way I would approach using ChatGPT to edit anything.\nI'm currently working on guidance for essay writing for students and I\nthink my experience here has taught me that I wouldn't ask it to edit\nanything directly but instead to give suggestions alongside the\noriginal. For the purposes of transcription correction, that process\nmakes it time-consuming but for an essay or any other piece of writing,\nit would ensure you're making active choices.\n\nAnother consideration is privacy. If you upload your transcripts, you're\nessentially giving OpenAI your lecture to help train its LLM [unless you\nchange the default\nsettings](https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt).\nWhether you care about that is up to you, but make a conscious choice.\n\nAnd finally, none of this changes the fact that the problem with the\nworkload involved with transcription will still be higher for people\nworking in their second language and those who have regional accents and\nthat academic workload modelling is a complete joke.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":false,"css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.21","date-format":"long","resources":["images/**","files/**"],"theme":{"light":"cosmo","dark":"slate"},"toggle":true,"title":"Using ChatGPT for learning & teaching: Correcting auto-transcripts","author":"Emily Nordmann","date":"2023-07-23","slug":"using-chatgpt-for-learning-teaching-correcting-auto-transcripts"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}